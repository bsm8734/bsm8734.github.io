<!DOCTYPE html><html lang="en" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="theme" content="Chirpy v2.7.2"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Gradient Descent Methods" /><meta name="author" content="Bae Soomin" /><meta property="og:locale" content="en_US" /><meta name="description" content="[DAY 12] Gradient Descent Methods" /><meta property="og:description" content="[DAY 12] Gradient Descent Methods" /><link rel="canonical" href="https://bsm8734.github.io/posts/bc-d012-2-dlbasic-optimization-gradient-descent-methods/" /><meta property="og:url" content="https://bsm8734.github.io/posts/bc-d012-2-dlbasic-optimization-gradient-descent-methods/" /><meta property="og:site_name" content="Always Awake Sally" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-02-02T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Gradient Descent Methods" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@Bae Soomin" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"Bae Soomin"},"description":"[DAY 12] Gradient Descent Methods","url":"https://bsm8734.github.io/posts/bc-d012-2-dlbasic-optimization-gradient-descent-methods/","@type":"BlogPosting","headline":"[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Gradient Descent Methods","dateModified":"2021-03-30T03:40:57+09:00","datePublished":"2021-02-02T00:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://bsm8734.github.io/posts/bc-d012-2-dlbasic-optimization-gradient-descent-methods/"},"@context":"https://schema.org"}</script><title>[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Gradient Descent Methods | Always Awake Sally</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="preload" href="/assets/css/post.css" as="style"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="/assets/js/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/my_image/Sally_wallpaper.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Always Awake Sally</a></div><div class="site-subtitle font-italic">24ì‹œê°„ì´ ëª¨ìë¼</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/tabs/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tabs/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/tabs/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/tabs/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/bsm8734" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['bsm8734','naver.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Gradient Descent Methods</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Gradient Descent Methods</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Tue, Feb 2, 2021, 12:00 AM +0900" > Feb 2 <i class="unloaded">2021-02-02T00:00:00+09:00</i> </span> by <span class="author"> Bae Soomin </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Tue, Mar 30, 2021, 3:40 AM +0900" > Mar 30 <i class="unloaded">2021-03-30T03:40:57+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1881 words">10 min</span></div></div><div class="post-content"><h2 id="day-12-gradient-descent-methods"><strong>[DAY 12] Gradient Descent Methods</strong></h2><hr /><h3 id="gradient-descentì˜-ì¢…ë¥˜"><strong>Gradient Descentì˜ ì¢…ë¥˜</strong></h3><ul><li>Stochastic gradient descent<li>Mini-batch gradient descent<li>Batch gradient descent</ul><h4 id="stochastic-gradient-descent"><strong>Stochastic gradient descent</strong></h4><ul><li>ì—¬ëŸ¬ ë°ì´í„°ê°€ ìˆì„ ë•Œ, í•œë²ˆì— í•˜ë‚˜ì˜ ë°ì´í„°(<strong>single sample</strong>)ì— ëŒ€í•´ì„œë§Œ gradientë¥¼ êµ¬í•˜ê³ , ê·¸ gradientë¥¼ í†µí•´ì„œ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸ â¡ ë°˜ë³µ</ul><hr /><h4 id="mini-batch-gradient-descent"><strong>Mini-batch gradient descent</strong></h4><ul><li>ë§ì´ ì‚¬ìš©ë¨<li>batch sizeì˜ ìƒ˜í”Œì„ í•œë²ˆì— í™œìš©í•˜ì—¬ gradient descent êµ¬í•˜ê³ , ì´ê²ƒì„ ì—…ë°ì´íŠ¸ â¡ ë°˜ë³µ(ì´í›„ ì „ì²´ì—ì„œ ë‹¤ì‹œ ë°ì´í„° ëœ¯ì–´ì„œ!)</ul><hr /><h4 id="batch-gradient-descent"><strong>Batch gradient descent</strong></h4><ul><li>í•œë²ˆì— ëª¨ë“  ë°ì´í„°ë¥¼ ë‹¤ ì‚¬ìš©<li>ëª¨ë“  gradientì˜ í‰ê· ì„ ê°€ì§€ê³  ì—…ë°ì´íŠ¸<li>ë„¤íŠ¸ì›Œí¬, GPU í„°ì§€ê¸° ì¢‹ìŒ ğŸ’¥</ul><hr /><h4 id="batch-size-ë¬¸ì œ"><strong>batch size ë¬¸ì œ</strong></h4><ul><li>batch sizeëŠ” êµ‰ì¥íˆ ì¤‘ìš”í•œ íŒŒë¼ë¯¸í„° ì¤‘ í•˜ë‚˜<li>í° batch size â¡ <strong>sharp minimum</strong>ì— ë„ë‹¬<li>ì‘ì€ batch size â¡ <strong>flat minimum</strong>ì— ë„ë‹¬(âœ” good)</ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/sources/2021-02-03-01-27-34.png" alt="17" /></p><ul><li>batch sizeë¥¼ ì¤„ì´ë©´ ì¼ë°˜ì ìœ¼ë¡œ generalizationì´ ì¢‹ì•„ì§ì„ ì‹¤í—˜ì ìœ¼ë¡œ ë³´ì—¬ì¤Œ<li>â¡ â€œí° ë°°ì¹˜ì‚¬ì´ì¦ˆë¥¼ ì–´ë–»ê²Œ í™œìš©í• ê²ƒì´ëƒâ€ ì¤‘ìš”<li><strong>Flat Minimum</strong><ul><li>training ì—ì„œ ì¢€ ë©€ì–´ì ¸ë„ testì—ì„œ ì ë‹¹íˆ ë‚®ì€ ê°’ì´ ë‚˜ì˜´<li>trainì—ì„œ ì˜ë˜ë©´ testì—ì„œë„ ì–´ëŠì •ë„ ì˜ë˜ëŠ” ê²ƒì„ í™•ì¸<li>generalization performanceê°€ ë†’ìŒ</ul><li><strong>Sharp Minimun</strong><ul><li>training ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì–»ì–´ì§€ëŠ” ê°’(loss, acc) ë“¤ì´ test ê¸°ì¤€ìœ¼ë¡œëŠ” í¬ê²Œ ë‹¤ë¥´ê²Œ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ<li>generalization performanceê°€ ë‚®ìŒ</ul></ul><hr /><h3 id="gradient-descent-methods"><strong>Gradient Descent Methods</strong></h3><ul><li>Stochastic gradient descent<li>Momentum<li>Nesterov accelerated gradient<li>Adagrad<li>Adadelta<li>RMSprop<li>Adam</ul><blockquote><p>loss function ì •ì˜í•˜ê³  ë‚˜ë©´, í¸ë¯¸ë¶„ì„ ì†ìœ¼ë¡œ ê³„ì‚°í•˜ì§€ ì•Šê³ , Automatic Differentiation(ìë™ë¯¸ë¶„ê³„ì‚°) ì‚¬ìš©<br /> tensorflow, pytorchâ€¦ ë“±ì€ ëª¨ë‘ ìë™ë¯¸ë¶„ì„ ì§€ì›<br /> ì´ì œ optimizerë¥¼ ê³¨ë¼ì¤˜ì•¼ í•˜ë¯€ë¡œ, ê°ê°ì´ ì™œ ë°œì „í–ˆëŠ”ì§€, ì–´ë–¤ ì„±ì§ˆì„ ê°€ì§€ëŠ”ì§€ ì•Œì•„ì•¼í•¨</p></blockquote><h3 id="stochastic-gradient-descent-1"><strong>(Stochastic) Gradient Descent</strong></h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/sources/2021-02-03-01-34-48.png" alt="19" /></p><ul><li>$W$: ì‹ ê²½ë§ì˜ weight (10ë§Œê°œë¼ë©´, í¬ê¸°ê°€ 10ë§Œì¸ ë²¡í„°ì¼ ê²ƒ)<li>$g$ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì¤Œ<li>ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•: lr(learning rate)ë§Œí¼ ê³±í•´ì„œ ë¹¼ì¤Œ<li>learning rate ì ì ˆíˆ ì¡ê¸°ê°€ ì–´ë ¤ì›€</ul><blockquote><p>squared lossë¥¼ í™œìš©í•˜ê²Œ ë˜ë©´, í° lossë¥¼ ì œê³±í•´ì„œ ì¦í­ì‹œí‚´(MSE)<br /> â¡ ë§ì´ í‹€ë¦¬ëŠ” ë¶€ë¶„ì„ ë” ì˜ ë§ì¶”ê²Œ ë¨<br /> â¡ ìƒëŒ€ì ìœ¼ë¡œ ëœ í‹€ë¦¬ëŠ” ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ëœ ì§‘ì¤‘í•˜ê²Œ ë¨<br /> â¡ ê·¸ë˜ì„œ ì•„ì£¼ í° outlierê°€ ê»´ìˆë‹¤ë©´ MSEë¥¼ ì‚¬ìš©í•˜ëŠ”ê²ƒì´ ì¢‹ì§€ ì•ŠìŒ</p></blockquote><hr /><h3 id="momentum"><strong>Momentum</strong></h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/sources/2021-02-03-01-35-01.png" alt="20" /></p><ul><li>momentum : ê´€ì„±<li>ê°™ì€ gradient descentë¥¼ ì‚¬ìš©í•˜ëŠ”ë°ë„ <strong>ë” ë¹ ë¥´ê²Œ í•™ìŠµ</strong>í•  ìˆ˜ ìˆëŠ” optimization í…Œí¬ë‹‰<li>ì–´ë–¤ ìª½ìœ¼ë¡œ íë¥´ë˜ ì •ë³´ëŠ” ë‹¤ìŒë²ˆ gradientê°€ ì¡°ê¸ˆ ë‹¤ë¥´ê²Œ íë¥´ë”ë¼ë„, ì´ì „ì— íë¥´ë˜ ë°©í–¥ì„ ì–´ëŠì •ë„ ìœ ì§€<li><strong>ëª¨ë©˜í…€ì´ í¬í•¨ëœ gradientë¡œ ì—…ë°ì´íŠ¸</strong> ì‹œí‚¤ëŠ” ê²ƒ<li>ì¥ì : <strong>í•œë²ˆ íë¥´ë˜ ë°©í–¥ì„ ì–´ëŠì •ë„ ìœ ì§€</strong>ì‹œì¼œì¤„ ìˆ˜ ìˆìŒ(ë‹¤ìŒ íšŒì°¨ì˜ gradientê°€ ì¡°ê¸ˆ ë‹¤ë¥´ë”ë¼ë„)<ul><li>â¡ gradientê°€ êµ‰ì¥íˆ ì˜¤ë½ê°€ë½í•˜ëŠ” ê²½ìš°ì—ë„, ì–´ëŠì •ë„ ì˜ í•™ìŠµëœ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´</ul></ul><blockquote><p><strong>minibatch trainingì—ì„œ ëª¨ë©˜í…€ì´ ì¢‹ì€ ì´ìœ </strong> âœ” ëª¨ë©˜í…€: â€œì´ì „ì˜ gradientë¥¼ í™œìš©(ë°˜ì˜)í•´ì„œ ë‹¤ìŒë²ˆì—ë„ ì“°ê² ë‹¤â€ â¡ ë°ì´í„°ë¥¼ í•œë²ˆì— ë§ì´ ë³´ëŠ” íš¨ê³¼!<br /> â¡ í˜ëŸ¬ì˜¨ gradient ì •ë³´ê°€ ë‹¤ìŒì— ì“°ì´ì§€ ì•Šìœ¼ë©´, í•˜ë‚˜ì˜ ë°°ì¹˜ëŠ” ë‹¨ìˆœíˆ ì‘ì€ ì˜ì—­ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë°ì´í„°ë¡œì„œ í™œìš©ë¨<br /> â¡ ë°˜ë©´, SGDë§Œ ìˆë‹¤ë©´, ë§ì€ iterationì´ ìˆì–´ì•¼, ëª¨ë“  ë°ì´í„°ê°€ ìˆ˜ë ´í•  ë•Œê¹Œì§€ ê°ˆ ìˆ˜ ìˆìŒ</p></blockquote><p>ì¡°ê¸ˆë” ì˜ ì´í•´í•´ë³´ìâ€¦</p><hr /><h3 id="nesterov-accelerated-gradient"><strong>Nesterov Accelerated Gradient</strong></h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/sources/2021-02-03-01-35-23.png" alt="21" /></p><ul><li>ëª¨ë©˜í…€ê³¼ ë¹„ìŠ·í•œ ì»¨ì…‰<li>ê²°êµ­, aë¼ëŠ” accumulate gradientê°€ gradient descent ì—­í• ì„ í•¨<li>gradientë¥¼ ê³„ì‚°í•  ë•Œ lookahead gradient ì‚¬ìš©</ul><blockquote><p>Momentum) í˜„ì¬ ì§€ê¸ˆ ì£¼ì–´ì ¸ìˆëŠ” íŒŒë¼ë¯¸í„°ì—ì„œ gradientë¥¼ ê³„ì‚° â¡ ê·¸ gradientë¥¼ ê°€ì§€ê³  momentumì„ accumultaion<br /> NAG) í•œë²ˆ ì´ë™í•¨ â¡ aë¼ëŠ” í˜„ì¬ ì •ë³´ë¼ëŠ”ê²Œ ìˆìœ¼ë©´, ê·¸ ë°©í–¥ìœ¼ë¡œ í•œë²ˆ ê°€ë³´ê¸° â¡ ê·¸ ê³³ì—ì„œì˜ gradientë¥¼ ê³„ì‚°í•œ ê²ƒì„ ê°€ì§€ê³  accumulateí•˜ê¸°</p></blockquote><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/sources/2021-02-03-01-35-41.png" alt="22" /></p><ul><li><strong>ëª¨ë©˜í…€ì˜ ë¬¸ì œ</strong>: <u>ê´€ì„±ì´ë¼ê³  ìƒê°í•˜ë©´, local minimumì— converging(ìˆ˜ë ´)ì„ ëª»í•¨ â¡ ê³„ì† ì§€ë‚˜ì¹¨</u><li><strong>NAG</strong>: í•œë²ˆ ì§€ë‚˜ê°„ ê³³ì—ì„œì˜ gradientë¥¼ ê³„ì‚°í•˜ë‹ˆê¹Œ local minimaê°€ í•œìª½ ì•„ë˜ë¡œ í˜ëŸ¬ê°€ëŠ” íš¨ê³¼<ul><li>ë´‰ìš°ë¦¬ì— <strong>í›¨ì”¬ ë¹ ë¥´ê²Œ ìˆ˜ë ´(Convergence)</strong></ul></ul><p>ëª¨ë¥´ê² ë‹¤</p><blockquote><p>ì—¬ê¸°ê¹Œì§€ëŠ” ê´€ì„±ì„ ì´ìš©í•œ ë°©ë²•</p></blockquote><hr /><h3 id="adagrad"><strong>Adagrad</strong></h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/sources/2021-02-03-01-36-07.png" alt="23" /></p><ul><li>NN íŒŒë¼ë¯¸í„°ê°€ ë§ì´ ë°”ë€Œì—ˆëŠ”ì§€, ì ê²Œ ë°”ë€Œì—ˆëŠ”ì§€ í™•ì¸<li>ì ê²Œ ë³€í•œê±´ ë” í¬ê²Œ ë³€í•˜ê²Œ í•˜ê³ , í¬ê²Œ ë³€í•œê±´ ë” ì‘ê²Œ ë³€í•˜ê²Œ í•¨<li><strong>ë¬¸ì œ</strong>: $G_t$ê°€ ê³„ì† ì»¤ì§<ul><li>$G$ê°€ ê³„ì† ì»¤ì§€ë©´ ë¶„ëª¨ê°€ ë¬´í•œëŒ€ë‹ˆê¹Œ $W ì—…ë°ì´íŠ¸ê°€ ì•ˆì´ë¤„ì§ˆ ê²ƒ<li>â¡ ë’¤ë¡œ ê°ˆìˆ˜ë¡ í•™ìŠµì´ ì ì  ì•ˆë˜ëŠ” ë¬¸ì œì ì´ ë°œìƒ</ul><li><del>ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ë¥¸(ë’¤)ë°©ë²•ì´ ìˆìŒ</del><li>Sum of gradient squares: ì–¼ë§Œí¼ ë³€í–ˆëŠ”ì§€ë¥¼ ì œê³±í•´ì„œ ë”í•œê²ƒ â¡ ê³„ì† ì»¤ì§ˆ ê²ƒ<li>â¡ ì»¤ì§„ë‹¤ëŠ”ê±´, ì§€ê¸ˆê¹Œì§€ ë§ì´ ë³€í–ˆë‹¤ëŠ” ì˜ë¯¸ì´ê³ , ì´ë¥¼ ì—­ìˆ˜ì— ë„£ìœ¼ë‹ˆê¹Œ<li>â¡ <strong>ë§ì´ ë³€í•œê±´ ì ê²Œë³€í•˜ê³ , ì ê²Œë³€í•œê±´ ë§ì´ ë³€í•˜ê²Œ ë¨</strong></ul><hr /><h3 id="adadelta"><strong>Adadelta</strong></h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/sources/2021-02-03-01-36-31.png" alt="24" /></p><ul><li>Adagradê°€ ê°€ì§€ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì ì“°ì„ â¡ $G_t$ê°€ ê³„ì† ì»¤ì§€ëŠ” í˜„ìƒì„ ë§‰ê³ ì í•¨<li>AdadeltaëŠ” Adagradì—ì„œ ê°€ì§€ê³  ìˆë˜, $lr$ì´ $G_t$ë¡œ í‘œí˜„ë¨ìœ¼ë¡œì¨ ìƒê¸°ëŠ” Monotonically Decreasing Propertyë¥¼ ë§‰ëŠ” ë°©ë²•<li><strong>ê°€ì¥ ì‰¬ìš´ ë°©ë²•</strong><ul><li>í˜„ì¬ íƒ€ì„ìŠ¤í… tê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì–´ëŠ ì •ë„ì˜ windowì‚¬ì´ì¦ˆ ë§Œí¼ì˜ íŒŒë¼ë¯¸í„°, ì‹œê°„ì— ëŒ€í•œ gradient ì œê³±ì˜ ë³€í™”ë¥¼ ë³´ê¸°<li><strong>ë¬¸ì œ</strong>: ìœˆë„ìš° ì‚¬ì´ì¦ˆê°€ 100ì´ë©´, ì´ 100ì´ë¼ëŠ” ìœˆë„ìš° ì‚¬ì´ì¦ˆë§Œí¼ì€ ê³„ì† ì •ë³´ë¥¼ ë“¤ê³ ìˆì–´ì•¼í•œë‹¤ëŠ” ê²ƒ<ul><li>â¡ íŒŒë¼ë¯¸í„° ì–‘ì´ ì•„ì£¼ ë§ìœ¼ë‹ˆê¹Œ ê·¸ëƒ¥ ì´ë ‡ê²Œ í•˜ë©´ GPU í„°ì§€ê¸° ì¢‹ìŒ!</ul><li><strong>í•´ê²°</strong>: Exponential Moving Average</ul><li><strong>EMA</strong><ul><li>ì–´ë–¤ ê°’ì´ ìˆì„ ë–„, ê°ë§ˆì™€ ì´ì „ê°’ì— ê°ë§ˆì™€ ê³±í•˜ê³ , ì˜´ ë§ˆì´ë„ˆìŠ¤ ê°ë§ˆ ë§Œí¼ì„ ë”í•´ì£¼ë©´ ì–´ëŠì •ë„ time window ë§Œí¼ì˜ ê°’ì„ ì €ì¥í•˜ê³ ìˆëŠ”, ê·¸ê²ƒì— ëŒ€í•œ í•©ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆê²Œ ë¨</ul><li><strong>EMA of difference squares</strong>: ì‹¤ì œ ë³€í™”ì‹œí‚¤ë ¤ëŠ” weightì˜ ë³€í™”ê°’ â¡ ê·¸ë˜ì„œ lrì´ ì—†ì–´ë„ ì–´ëŠì •ë„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê² ë‹¤ëŠ” ê²ƒ</ul><blockquote><p>adadeltaëŠ” learning rateê°€ ì—†ìŒ<br /> ë°”ê¿€ ìˆ˜ ìˆëŠ” ìš”ì†Œê°€ ë§ì´ ì—†ê¸° ë–„ë¬¸ì— ì˜ í™œìš©ë˜ì§€ ì•ŠìŒ</p></blockquote><p>ëª¨ë¥´ê² ìŒ</p><hr /><h3 id="rmsprop"><strong>RMSprop</strong></h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/sources/2021-02-03-01-36-45.png" alt="25" /></p><ul><li>$G_t$ë¥¼ ê·¸ëƒ¥ ë”í•˜ì§€ ì•Šê³ , Exponential Moving Average ë”í•´ì¤Œ<li>ê·¸ê²ƒì„ ë¶„ëª¨í…€ì— ë„£ê³  step sizeë¥¼ ë„£ìŒ</ul><blockquote><p>ë§ì´ ì‚¬ìš©<br /> ë…¼ë¬¸ì„ í†µí•´ì„œ ì œì•ˆëœ ê²ƒì´ ì•„ë‹Œ, practical ì œì•ˆ</p></blockquote><p>ëª¨ë¥´ê² ìŒ</p><hr /><h3 id="adam"><strong>Adam</strong></h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/sources/2021-02-03-01-37-07.png" alt="26" /></p><ul><li>ëª¨ë©˜í…€ê³¼ adaptive learning rateë¥¼ í•©ì¹œ ê²ƒ â¡ ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì¢‹ìŒ<li><strong>íŠ¹ì§•</strong><ul><li><strong>gradientì˜ í¬ê¸°ê°€ ë³€í•¨ì— ë”°ë¼ì„œ</strong> (í˜¹ì€ gradientì˜ squareì˜ í¬ê¸°ì— ë”°ë¼ì„œ) <strong>adaptiveí•˜ê²Œ learning rateë¥¼ ë°”ê¿ˆ</strong><li>ì´ì „ì˜ gradient ì •ë³´ì— í•´ë‹¹í•˜ëŠ” ëª¨ë©˜í…€ ë‘ê°œë¥¼ í•©ì¹œ ê²ƒ</ul></ul><blockquote><p><strong>4ê°œì˜ ì¤‘ìš” íŒŒë¼ë¯¸í„°</strong> (ì–´ë–»ê²Œ ì¡°ì •í•  ì§€ê°€ ì¤‘ìš”)</p><ul><li>$\beta_1$: ëª¨ë©˜í…€ì„ ì–¼ë§ˆë‚˜ ìœ ì§€ì‹œí‚¬ ê²ƒì¸ê°€<li>$\beta_2$: Gradient Squaresì— ëŒ€í•œ EMA ì •ë³´<li>$\eta$ (=lr, learning rate)<li>$\epsilon$ (=ì…ì‹¤ë¡ )</ul></blockquote><blockquote><p><strong>adaptive learning rate</strong><br /> ì–´ëŠ íŒŒë¼ë¯¸í„°ì—ì„œëŠ” lrì„ ì¤„ì´ê³  ì–´ë–¤ íŒŒë¼ë¯¸í„°ì˜ lrì€ ë†’ì¼ ìˆ˜ ìˆìŒ<br /> ë”°ë¼ì„œ, ê°™ì€ base learning rateë¥¼ ê°€ì§€ê³  ìˆë‹¤ í•˜ë”ë¼ë„ í›¨ì”¬ ë” ë¹ ë¥´ê²Œ í•™ìŠµ ê°€ëŠ¥</p></blockquote></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%B6%80%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%94%84-ai-tech/'>ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech</a>, <a href='/categories/deeplearning-basic/'>DeepLearning_Basic</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/dl/" class="post-tag no-text-decoration" >DL</a> <a href="/tags/ml/" class="post-tag no-text-decoration" >ML</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Gradient Descent Methods - Always Awake Sally&url=https://bsm8734.github.io/posts/bc-d012-2-dlbasic-optimization-gradient-descent-methods/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Gradient Descent Methods - Always Awake Sally&u=https://bsm8734.github.io/posts/bc-d012-2-dlbasic-optimization-gradient-descent-methods/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Gradient Descent Methods - Always Awake Sally&url=https://bsm8734.github.io/posts/bc-d012-2-dlbasic-optimization-gradient-descent-methods/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/bc-stage1-d002-lecture/">[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / P Stage1] Lecture2 - Dataset & Data Generation</a><li><a href="/posts/bc-stage1-d002-TIL/">[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / P Stage1] Day2 TIL</a><li><a href="/posts/bc-d002-5-python-condition-loop/">[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day2] íŒŒì´ì¬ ì¡°ê±´ë¬¸, ë°˜ë³µë¬¸</a><li><a href="/posts/bc-d002-6-python-string/">[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day2] íŒŒì´ì¬ String</a><li><a href="/posts/bc-d002-today/">[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day2] Today</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/today/">today</a> <a class="post-tag" href="/tags/dl/">DL</a> <a class="post-tag" href="/tags/ml/">ML</a> <a class="post-tag" href="/tags/math/">Math</a> <a class="post-tag" href="/tags/cv/">CV</a> <a class="post-tag" href="/tags/imageclassification/">ImageClassification</a> <a class="post-tag" href="/tags/graph/">Graph</a> <a class="post-tag" href="/tags/%EA%B5%AC%EA%B8%80-%EC%8A%A4%ED%84%B0%EB%94%94%EC%9E%BC/">êµ¬ê¸€ ìŠ¤í„°ë””ì¼</a> <a class="post-tag" href="/tags/nlp/">NLP</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/bc-d011-3-dlbasic-neural-net-mlp/"><div class="card-body"> <span class="timeago small" > Feb 1 <i class="unloaded">2021-02-01T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day11] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ NN & MLP</h3><div class="text-muted small"><p> [DAY 11] NN &amp; MLP Neural Network? ì‹ ê²½ë§, ë‡Œë¥¼ ëª¨ë°©í•˜ê³ ì í•˜ëŠ” ì‹œìŠ¤í…œ í•¨ìˆ˜ì  ì ‘ê·¼: ì´ë¯¸ì§€ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ë²¡í„°, í–‰ë ¬ê³± ë“±ì˜ í•¨ìˆ˜ë¥¼ ëª¨ë°©í•˜ëŠ” Function approximator ë¼ê³  ë³´ëŠ” ê²ƒ function approximator: parameterë¥¼ ì´ìš©í•˜ì—¬ ì‹¤ì œ ê°’ì— approximateí•˜...</p></div></div></a></div><div class="card"> <a href="/posts/bc-d012-1-dlbasic-optimization/"><div class="card-body"> <span class="timeago small" > Feb 2 <i class="unloaded">2021-02-02T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization</h3><div class="text-muted small"><p> [DAY 12] Optimization(ìµœì í™”) Gradient Descent local miniumì„ ì°¾ê¸° ìœ„í•œ 1ì°¨ ë°˜ë³µ ìµœì í™” ì•Œê³ ë¦¬ì¦˜(1ì°¨ ë¯¸ë¶„ë§Œì„ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©) ë¯¸ë¶„ í•¨ìˆ˜ì˜ ìµœì†Œê°’ ìµœì í™” ëª©ì°¨ Generalization Under-fitting vs. over-fitting Cross validation ...</p></div></div></a></div><div class="card"> <a href="/posts/bc-d012-3-dlbasic-optimization-regularization/"><div class="card-body"> <span class="timeago small" > Feb 2 <i class="unloaded">2021-02-02T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Regularization</h3><div class="text-muted small"><p> [DAY 12] Regularization í•™ìŠµì— ë°˜ëŒ€ë˜ë„ë¡ ê·œì œë¥¼ ê±¸ê¸° í•™ìŠµì„ ë°©í•´í•˜ì—¬, train data ë¿ë§Œì•„ë‹ˆë¼ test dataì—ë„ ì˜ ë™ì‘í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìˆìŒ ì¼ì¢…ì˜ ë„êµ¬ë“¤ì— ëŒ€í•˜ì—¬ ì„¤ëª… (ì‚¬ìš©í•˜ë©´ ì˜ë ìˆ˜ë„ ìˆìŒ) ì¢…ë¥˜ Early stopping Parameter norm penalty ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/bc-d012-1-dlbasic-optimization/" class="btn btn-outline-primary"><p>[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization</p></a> <a href="/posts/bc-d012-3-dlbasic-optimization-regularization/" class="btn btn-outline-primary"><p>[ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech / Day12] ë”¥ëŸ¬ë‹ ê¸°ì´ˆ Optimization - Regularization</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> Â© 2021 <a href="https://github.com/username">BaeSoomin</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/today/">today</a> <a class="post-tag" href="/tags/dl/">DL</a> <a class="post-tag" href="/tags/ml/">ML</a> <a class="post-tag" href="/tags/math/">Math</a> <a class="post-tag" href="/tags/cv/">CV</a> <a class="post-tag" href="/tags/imageclassification/">ImageClassification</a> <a class="post-tag" href="/tags/graph/">Graph</a> <a class="post-tag" href="/tags/%EA%B5%AC%EA%B8%80-%EC%8A%A4%ED%84%B0%EB%94%94%EC%9E%BC/">êµ¬ê¸€ ìŠ¤í„°ë””ì¼</a> <a class="post-tag" href="/tags/nlp/">NLP</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } }, tex2jax: { inlineMath: [ ['$', '$'] ], displayMath: [ ['$$', '$$'] ], processEscapes: true, } }); MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://bsm8734.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
