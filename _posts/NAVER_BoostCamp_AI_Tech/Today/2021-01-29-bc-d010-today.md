---
title: "[부스트캠프 AI Tech / Day10] Today"
data: 2021-01-29 21:31:00 +0900
categories: [네이버 부스트캠프 AI Tech, Today]
tags: [today]
---


## **피어세션 정리**

### 제안

- `엠제이`: 자유롭게 슬랙에 카톡하듯이 질문했으면 좋겠습니다
- `서폿`: 중요한 것은 깃허브 이슈
- `서폿`: 질문자 답변자가 독스에 짤막하게 정리식으로 적어주기

### 피어세션 시간 고찰

- 깃허브 ➡ 생각을 많이해서 정리
- 피어세션 ➡ 자유롭게 질문하는 분위기
- `펭귄` ➡ Further Question 은 피어세션에서 다 함께 얘기해 보았으면 좋겠음

### 논의

- `펭귄`: 몬테카를로 방법을 활용하여 원주율에 대한 근사값을 어떻게 구할 수 있을까요?
  - `엠제이`: 정사각형안에 직접 점을 찍어보는 방식으로 해서 근사시킬 수 있습니다
    - https://statkclee.github.io/r-algorithm/r-monte-carlo-pi.html
- `히스`: 표본분산을 구할 때 N 이 아니라 N-1인 이유?
  - `펭귄`: https://m.blog.naver.com/sw4r/221021838997
  - 또한, 일반적으로 파라미터 예측치의 자유도는 파라미터를 예측하기 위해 중간과정에서 사용되는 파라미터의 수를 전체 독립적인 정보의 수에서 빼줘야 한다고 함. 그러한 예로써, 샘플 분산은 N-1 자유도를 가지는데, 이유는 N개의 랜덤 정보에서 중간 과정에서 샘플 평균을 구해서 샘플 분산을 구해야 하기 때문에 그 파라미터 개수인 1개를 뺀 N-1이 된다는 것임
  - `샐리`: https://m.blog.naver.com/ao9364/222023124818
- `펭귄`: 분류 문제에서 softmax 함수가 사용되는 이유가 뭘까?
  - `샐리`: https://lv99.tistory.com/7
- `샐리`: 엔트로피?
  - `원딜`: 불순도의 감소폭을 크게 만들어주는…?
  - `서폿`: http://melonicedlatte.com/machinelearning/2019/12/20/204900.html
- `서폿` min-max scaling?
  - `서폿`: min-max 정규화
    - https://wotres.tistory.com/entry/min-max-scaling-%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95-in-python?category=930448
- `원딜`: 소프트맥스를 확률로 해석? 아니면 의도적으로 그렇게 제작?
- `서폿` 그래서 엔트로피가 무엇인가?
  - [0.5 0.5] - 엔트로피 높음
  - [0.1 0.9] - 엔트로피 낮음
  - `서폿`: http://melonicedlatte.com/machinelearning/2019/12/20/204900.html
- `샐리`: 근래 ReLU를 자주 사용하는 이유?
  - `펭귄`: 기울기 소실 문제 해결 ex)leaky ReLU
- `펭귄`: softmax 함수의 결과값을 분류 모델의 학습에 어떤식으로 사용할 수 있을까요?
- `샐리`: 아래 링크의 그래프에서 파란색 점들이 의미하는 바는?
  - `엠제이`: http://norman3.github.io/prml/docs/chapter01/5

[피어세션 링크 date:2021.01.29. 기준 issue](https://github.com/boostcamp-ai-tech-4/peer-session/issues)

---

## **과제 진행 상황**

- 과제 현황
  - [X] (퀴즈) 통계학 맛보기 1~5

---

## **오늘의 한마디**

- 체크아웃을 잘하자...
- 효율적으로 공부하기