---
title: "[AI 면접 Cheat Sheet] Deep Learning - 문제편"
data: 2021-03-20 20:30:00 +0800
categories: [Cheat_Sheet, DL]
tags: [DL, CheetSheet]
use_math: True
---


## **면접 대비용 Cheet Sheet - 문제편**

---

- **활성화함수 사용하는 이유?**
  - 활성화 함수를 사용하는 이유는 크게 두가지가 있습니다. 첫번째는 모델 레이어들 사이에 존재하면서 학습을 돕는 역할을 하고, 두번째 역할은 모델의 가장 마지막 출력에 관여하여, 출력의 형태를 변환시키는 역할을 합니다.
  - 선형 입력에 대해 비선형 입력으로 변환하기 위해서 사용합니다.
  - 비선형 입력으로 변환하는 경우, 신경망에 여러 레이어를 쌓을 수 있게 되므로, XOR 같은 문제를 해결하여, 기계학습을 가능하게 합니다.
- **Sigmoid Function의 장단점? 사용하지 않는 이유?**
  - 장점 1: 유연한 미분 값 가짐
    - 입력에 따라 값이 급격하게 변하지 않습니다.
  - 장점 2: 출력값의 범위가 0과 1 사이로 제한됨으로써 정규화 중 exploding gradient 문제 방지
  - 장점 3: 미분식이 단순한 형태 지님 / 깔끔한 예측값
    - 계산 값이 양 끝단으로 가까울수록 0과 1에 수렴합니다.
  - 단점 1: vanishing gradient 문제 발생
    - 입력이 아무리 커도 미분 값의 범위가 0과 1/4 사이로 제한됨으로써 층이 많을수록 gradient 값이 0에 수렴할 것입니다.
  - 단점 2: 출력의 중심이 0이 아님
    - 뉴런으로 들어오는 데이터가 항상 양수인 경우 gradient는 모두 양수 또는 음수가 됩니다. 이는 gradient 업데이트 중 지그재그로 변동하는 문제점이 발생합니다. 이 지그재그로 변동하는 gradient는 학습 효율성을 감소시킬 수 있습니다
  - 느린 exp 계산
  - zigzag 현상
- **ReLU의 장단점?**
  - 일부 정보는 과감히 무시하고 일부 정보는 수용하는 것을 통해 다른 활성화 함수에 비해 효율적인 결과를 보입니다.
  - 장점 1: 빠른 연산
    - 단지 비교 연산 1회를 통해 값을 구합니다.
    - 다른 활성화 함수에 비해 수렴 속도가 매우 빠릅니다.
  - 단점 1: 음수에 대한 대응
    - ReLU의 장점이 단점이 되는 순간입니다.
    - 값이 음수일 경우 학습을 하지 못합니다.
  - 가장 많이 사용함
  - non-linear하면서 가장 심플
  - exp 없이 단순하여, 수렴속도가 빠름
  - activation이 smooth한 구간에 걸리는 순간 w 없데이트 속도가 매우 느려짐 (그러나 렐루는 편미분(기울기)가 1로 일정하므로 빨라짐)
  - zigzag 현상 생김
- **파라미터와 하이퍼파라미터의 차이는?**
  - 파라미터: 모델 내부에서 결정되는 변수(weight, bias)
  - 하이퍼파라미터: 모델링할 때, 사용자가 직접 세팅해야하는 값(learning rate, epoch, iteration)
- **배치 처리를 하는 이유?**
  - 계산시 이득이 있기 때문
  - 수치 라이브러리 대부분이 큰 배열을 효율적으로 처리할 수 있도록 최적화되어있기 때문
    - ㅋ큰 배열을 한꺼번에 계산하는 것이 분할된 작은 배열을 여러번 계산하는 것보다 빠름
  - 큰 신경망에서는 데이터 전송이 병목으로 작용하는 경우가 있는데, 배치 처리를 통해서 버스에 주는 부하를 줄일 수 있음
    - 느린 I/O를 통해 데이터를 읽는 횟구가 줄어들어서, 빠른 CPU/GPU로 순수 계산을 수행하는 비율이 높아짐
- **loss function과 metric의 차이?**
  > 여기서 loss는 손실함수를 의미합니다. 모델을 훈련시킬때 이 손실 함수를 최소로 만들어주는 가중치들을 찾는 것을 목표로 삼습니다. 위 예에서는 손실함수로 MSE(mean squared error)를 사용했습니다. 손실함수로 MSE만 사용할 수 있는 것이 아니고, MAE(mean absolute error), hinge, categorical crossentropy, sparse categorical crossentropy, binary crossentropy 등도 사용할 수 있습니다. 자신이 훈련시키는 모델에 적합한 손실함수를 선택해주면 됩니다. 예를 들어, 10개의 클래스를 분류할 수 있는 분류기를 훈련시키는 경우에는 손실함수로 sparse categorical crossentropy를 사용할 수 있습니다.  
  > 반면 metric은 평가지표입니다. 검증셋에서 훈련된 모델의 성능을 평가할 때 어떤 평가지표로 평가할지를 결정해줍니다. 학습곡선을 그릴 때 손실함수와 평가지표를 에포크(epoch)마다 계산한 것을 그려주는데, 손실함수의 추이와 평가지표의 추이를 비교해보면서 모델이 과대적합(overfit) 또는 과소적합(underfit)되고 있는지 여부를 확인할 수 있습니다. 위 예에서는 평가지표로 MAE를 사용했습니다. 중요한 것은 평가지표로 어떤 것을 사용하더라도 모델 가중치의 업데이트에는 영향을 미치지 않는다는 사실입니다.
  - loss: 손실함수. 훈련셋과 연관. 훈련에 사용. 
  - metric: 평가지표. 검증셋과 연관. 훈련 과정을 모니터링하는데 사용. 
- **loss function cost function 차이?**
  - 그냥 순간순간의 loss를 판단할 땐 loss function 학습이 완료된 후에는 cost function을 확인